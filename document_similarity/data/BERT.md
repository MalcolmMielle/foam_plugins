# BERT

[BERT](https://en.wikipedia.org/wiki/BERT_(Language_model)) is a transformer-based machine learning technique, published in 2018, for natural language processing (NLP) pre-training developed by Google.

[Hugging face](https://huggingface.co/) hosts several [BERT pre-trained models](https://www.sbert.net/docs/pretrained_models.html)